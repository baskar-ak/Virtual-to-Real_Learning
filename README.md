# Virtual-to-Real Learning: Augmented Reality and Neural Networks
### Motivation / Problem Statement:
The acquisition of data in real-world is always challenging, resourse intensive and time-consuming. This involves setting up systems like cameras, sensors, etc. to capture the object and sometimes that system can be sophisticated to use, or the object can be hazardous, or the environment can be dangerous. Moreover neural network models typically require large amounts of data to train and generalize well. Gathering and preparing large volumes of data takes considerable effort and time. Furthermore, recognizing unique new world objects that are not present in the real world by neural networks is cumbersome as it involves creating the object physically, placing it in the real world, and collecting data.<br/>

### Objective:
* Use Augmented Reality (AR) to project and blend virtual objects onto real-world scene or background.
* Build and train a neural network model to learn from virtual objects to recognize real-world objects on live video stream.<br/>

### Methodology:
* *Augmenting virtual objects*: 4 traffic objects are chosen - Jersey barriers, Type II A-frames, Pedestrian crossing sign board, and a custom-made Duck crossing sign board. The duck crossing sign is a 'new world' object or an object that is rarely found in the real-world. The purpose of introducing the duck crossing sign board is to tackle the above problem and enable networks to learn such new world objects and recognize them in the real-world.
* *Marker Generation*: The traffic objects are projected onto a scene or background using ArUco markers. A dictionary composed of 50 markers and a marker size of 4x4 bits with marker ID 23 is chosen as the target marker.
* *Virutal object overlay*: Markers are placed on various real-world scene. Virtual traffic objects are then projected on these markers within the real-world background and forms a dataset.
* *Data collection*: Dataset for 4 traffic objects is generated by augmenting each traffic object onto various real-world scenes. There are 4 classes as there are four traffic objects.
* *Object recognition*: The collected dataset is used to train a convolutional neural network build using PyTorch to recognize real-world objects on a live stream.<br/>

### Solution Architecture:
<img src="" width="300"><br/>

### Results:
<img src="" width="300"><br/>
The model achieved an accuracy of 96% with a loss of 0.11.

### Limitations:
* The virtual objects used to augment onto the scenes are 2D images. Light, texture, shadow etc., of virtual objects may not match with the real-world background. Augmenting 3D objects created through Unity and other simulation engines would work better.
* Less training data was generated to train the deep networks due to time constraints.<br/>

### Conclusion:
Despite the challenges, this project shows that complexity in data acquisition can be greatly tackled using AR techniques. Networks can be easily trained to recognize unique objects in the virtual world and can then be transferred to real-world environments. By leveraging virtual-to-real learning, one can gather better data with ease and train robust neural networks.
